# Databricks notebook source
# MAGIC %md
# MAGIC ### ðŸ”— Links and Resources
# MAGIC [Python API Reference](https://spark.apache.org/docs/latest/api/python/reference/index.html)

# COMMAND ----------

# MAGIC %md
# MAGIC ### ðŸ“Œ Step by Step Approach
# MAGIC
# MAGIC The step-by-step approach breaks your code into clear, discrete stagesâ€”first ingest, then transform, then persistâ€”by assigning each intermediate result to a named variable. 
# MAGIC
# MAGIC That modular style makes it easy to inspect and debug at each point.

# COMMAND ----------

import pandas as pd

pd.read_csv("./data.csv")

# COMMAND ----------

df = spark.read.format("csv").load("./data.csv")

# COMMAND ----------

df_filter = df.filter("Age > 30")
df_filter.show()

# COMMAND ----------

df.write.format("csv").save("/path/to/directory/")

# COMMAND ----------

# MAGIC %md
# MAGIC ### ðŸ“Œ Chaining Methods
# MAGIC Method chaining is a â€œfluentâ€ interface pattern where each method returns an objectâ€”often the same instance or a new immutable oneâ€”so you can immediately call the next operation on it. 
# MAGIC
# MAGIC Instead of breaking your logic into named, intermediate variables, you stitch calls together in a linear flow that reads like a pipeline: each step consumes the output of the previous one. 
# MAGIC
# MAGIC This style makes the overall sequence of transformations concise and expressive, emphasizes the order of operations, and reduces boilerplateâ€”though for very complex or conditional logic you might still choose to pull out intermediate results for clarity or debugging.

# COMMAND ----------

spark.read.format("csv").load("/path/to/file.csv").filter("Age > 30").write.format("csv").save("/path/to/directory/")

# COMMAND ----------

# MAGIC %md
# MAGIC You can use backslashes to break a long method chain into readable, indented lines.
# MAGIC
# MAGIC In Python, a backslash (\) indicates that a statement continues onto the next line. Without it, Python would assume the code ends at the newline and youâ€™d get a syntax error.

# COMMAND ----------

spark.read.format("csv").load("/path/to/file.csv").\
filter("Age > 30").\
write.format("csv").save("/path/to/directory/")
